# Text Preprocessing Pipeline (Day 1 - NLP Project)
**NLP Project - Classical text cleaning and preprocessing using NLTK and spacy**

This project implement a classical NLP preprocessing pipeline:
- Lowercasing, punctuation removal
- Tokenization, stopword removal
- Stemming (Porter) and Lemmatization (WordNet)

### Libararies Used
- NLTK
- re
- pandas

### Files
- preprocessing.ipynb: Main notebook
- cleaned_text.json: sample output
- requirements.txt: Dependencies
- utils.py
- main.py

### How to run?
- Clone the package
- Create a virtual environment
- Install the dependencies
- Run the following code:
    'python main.py'

## Author
- Suel Ahmed
- Actively building a portfolio of real-world NLP Projects

**Part of my 20-Day MLP Spring Day#1**
